{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a40ee68",
   "metadata": {},
   "source": [
    "# Synthetic NF1 MRI Images - Train the FCC-GAN\n",
    "\n",
    "## 1. Project datasheet\n",
    "\n",
    "| Category | Value\n",
    "| --: | :-- |\n",
    "| Project | Synthetic NF1 MRI Images ` (syn26010238) ` |\n",
    "| Team | DCD ` (3430042) ` |\n",
    "| Competition | Hack4Rare 2021 |\n",
    "| Description | script to train FCC-GAN\n",
    "| Additional requirements | you need to have the dataset ` syn20608511 ` |\n",
    "\n",
    "## 2. Imports\n",
    "\n",
    "Project level imports include check of folders. It produces an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d2a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, mkdir\n",
    "from os.path import isdir, isfile, join\n",
    "from pickle import dump, load\n",
    "from random import shuffle\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import torch\n",
    "\n",
    "from config import Folder\n",
    "import constants\n",
    "import enum_handler\n",
    "from models import DCDDiscriminator, DCDGenerator\n",
    "from training_tools import weight_init, yield_x_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d2bd91",
   "metadata": {},
   "source": [
    "## 3. Constants\n",
    "\n",
    "These constants control the training workflow.\n",
    "\n",
    "| Variable name | type | Effect | Comments |\n",
    "| --: | :-: | :-- | :-- |\n",
    "| **ALLOW_CUDA** | bool | Whether or not to train on CUDA | This switch has no effect if cuda is not available |\n",
    "| **BATCH_SIZE** | int | Size of batches | In GPU mode size of GPU memory is a limitation. |\n",
    "| **DEPTH_BASE** | int | Base value for channel multiplication | Used to construct convolutional and transposed convolutional layers |\n",
    "| **EPOCH_COUNT** | int | Number of epoch to train | |\n",
    "| **FLAT_SIZE** | int | Size of the flat vector | It is used at the end of the discriminator model |\n",
    "| **GAUSSIAN_INIT** | bool | Whether or not to apply gaussian init on layers | It has no effect is models are laoded |\n",
    "| **IMG_CHANNELS** | int | Count of color channels for images | It is applied both for input and output images |\n",
    "| **IMG_HEIGHT** | int | Height of generated images | |\n",
    "| **IMG_WIDTH** | int | Width of generated images | |\n",
    "| **KERNEL_SIZE** | int | Size of the kernels to use | Convolutional and transposed convulational layers use the same kernel size |\n",
    "| **LEARNING_RATE** | float | Learning rate for optimizers | Both models are using the same learning rate |\n",
    "| **LOAD_MODEL** | str | Model name to load | If an empty string is given, a training from scratch is started |\n",
    "| **RANDOM_VECTOR_DIM0** | int | Dim 0 of the random vector | |\n",
    "| **VECTOR_DIMS** | tuple(int, int) | Further dimensons of the random vector | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOW_CUDA = True\n",
    "BATCH_SIZE = 4\n",
    "DEPTH_BASE = 16\n",
    "EPOCH_COUNT = 3000\n",
    "FLAT_SIZE = 992\n",
    "GAUSSIAN_INIT = True\n",
    "IMG_CHANNELS = 1\n",
    "IMG_HEIGHT = 530\n",
    "IMG_WIDTH = 162\n",
    "KERNEL_SIZE = 4\n",
    "LEARNING_RATE = 1e-4\n",
    "LOAD_MODEL = ''\n",
    "RANDOM_VECTOR_DIM0 = 128\n",
    "VECTOR_DIMS = (50, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32229c5e",
   "metadata": {},
   "source": [
    "## 4. Dataset\n",
    "\n",
    "### 4.1. Check or prepare dataset\n",
    "\n",
    "#### 4.1.1. Functions the prepare or load dataset if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df08cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_selected(patient_id : str, start : int =13, stop : int=15):\n",
    "    \"\"\"\n",
    "    Copy and normalize selected slices from dicom files\n",
    "    ===================================================\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_id : str\n",
    "        ID of the patient to copy images.\n",
    "    start : int, optional (13 if omitted)\n",
    "        First index of the dicomlist to copy.\n",
    "    stop : int, optional (14 if omitted)\n",
    "        Index in the dicomlist to stop copy.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "        Just like in case of any other Python slicing, stop index is not included.\n",
    "    \"\"\"\n",
    "    \n",
    "    dicom_files = get_dicomlist(patient_id)\n",
    "    count = len(dicom_files)\n",
    "    if count > 0:\n",
    "        for index, file_name in enumerate(dicom_files[start:stop]):\n",
    "            img = pydicom.dcmread(file_name).pixel_array\n",
    "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "            with open('{}/{}_{}_orig.pkl'\n",
    "                      .format(Folder.IMG_ORIGINAL.value, patient_id,\n",
    "                              start + index), 'wb') as outstream:\n",
    "                dump(img, outstream)\n",
    "            img = cv2.convertScaleAbs(img)\n",
    "            img = np.asarray(img, dtype=np.float32) / 255.0\n",
    "            with open('{}/{}_{}_normalized.pkl'\n",
    "                      .format(Folder.IMG_NORMALIZED.value, patient_id,\n",
    "                              start + index), 'wb') as outstream:\n",
    "                dump(img, outstream)\n",
    "\n",
    "\n",
    "def get_dicomlist(patient_id : str) -> list:\n",
    "    \"\"\"\n",
    "    Get list of existing DICOM files of a patient\n",
    "    =============================================\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_id : str\n",
    "        ID of the patient to get list of files.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        List of files.\n",
    "    \"\"\"\n",
    "\n",
    "    result = []\n",
    "    patient_root = join(Folder.CASES.value, 'WBMRI{}/DICOM/'.format(patient_id))\n",
    "    if isdir(patient_root):\n",
    "        directories = [join(patient_root, d) for d in listdir(patient_root)\n",
    "                         if isdir(join(patient_root, d))]\n",
    "        for directory in directories:\n",
    "            for file_name in listdir(directory):\n",
    "                full_path = join(directory, file_name)\n",
    "                if isfile(full_path) and full_path.endswith('.dcm'):\n",
    "                    result.append(full_path)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_patient_ids() -> list:\n",
    "    \"\"\"\n",
    "    Get list of patient IDs\n",
    "    =======================\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        List of patient IDs.\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    patients_files = [f for f in listdir(Folder.REPORT.value)\n",
    "                      if isfile(join(Folder.REPORT.value, f)) and f.endswith('.xls')]\n",
    "    for patient_file in patients_files:\n",
    "        result.append(patient_file.lstrip('wbmri_').rstrip('.xls'))\n",
    "    return result\n",
    "\n",
    "def load_image_np(file_name : str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load image as numpy.ndarray\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        File path to load.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The loaded image as numpy.ndarray.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_name, 'rb') as instream:\n",
    "        return np.expand_dims(np.expand_dims(load(instream), axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46edc8d9",
   "metadata": {},
   "source": [
    "#### 4.1.2. Check or prepare in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb6a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isdir(Folder.IMG_NORMALIZED.value):\n",
    "    if not isdir(Folder.IMG_ROOT.value):\n",
    "        mkdir(Folder.IMG_ROOT.value)\n",
    "    if not isdir(Folder.IMG_ORIGINAL.value):\n",
    "        mkdir(Folder.IMG_ORIGINAL.value)\n",
    "    if not isdir(Folder.IMG_NORMALIZED.value):\n",
    "        mkdir(Folder.IMG_NORMALIZED.value)\n",
    "    for patient_id in get_patient_ids():\n",
    "        copy_selected(patient_id)\n",
    "    print('Image data was just created.')\n",
    "else:\n",
    "    if len([f for f in listdir(Folder.IMG_NORMALIZED.value)]) == 0:\n",
    "        if not isdir(Folder.IMG_ORIGINAL.value):\n",
    "            mkdir(Folder.IMG_ORIGINAL.value)\n",
    "        for patient_id in get_patient_ids():\n",
    "            copy_selected(patient_id)\n",
    "        print('Image data was just created.')\n",
    "    else:\n",
    "        print('Image data already exists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0212e3",
   "metadata": {},
   "source": [
    "### 4.2. Load the dataset\n",
    "\n",
    "In fact image paths are loaded only but this is a good way to spare memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74058bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = [join(Folder.IMG_NORMALIZED.value, f) for f in listdir(Folder.IMG_NORMALIZED.value)\n",
    "                                                   if isfile(join(Folder.IMG_NORMALIZED.value, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68971e27",
   "metadata": {},
   "source": [
    "## 5. Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ae203",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if ALLOW_CUDA and torch.cuda.is_available() else 'cpu'\n",
    "print('Training on {}.'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a0d8f5",
   "metadata": {},
   "source": [
    "## 6. Model\n",
    "\n",
    "### 6.1. Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = DCDGenerator(IMG_CHANNELS, DEPTH_BASE, KERNEL_SIZE, (RANDOM_VECTOR_DIM0,*VECTOR_DIMS))\n",
    "discriminator = DCDDiscriminator(IMG_CHANNELS, DEPTH_BASE, KERNEL_SIZE, FLAT_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a44d5",
   "metadata": {},
   "source": [
    "### 6.2. Load pretrained if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff97b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MODEL != '':\n",
    "    if isfile(join(Folder.GENERATOR.value, LOAD_MODEL)) and isfile(join(Folder.DISCRIMINATOR.value, LOAD_MODEL)):\n",
    "        generator.load_state_dict(torch.load(join(Folder.GENERATOR.value, LOAD_MODEL)))        \n",
    "        discriminator.load_state_dict(torch.load(join(Folder.DISCRIMINATOR.value, LOAD_MODEL)))\n",
    "    else:\n",
    "        print('Trained models \"{}\" are not available here.'.format(LOAD_MODEL))\n",
    "else:\n",
    "    print('No trained models are loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb1fcf8",
   "metadata": {},
   "source": [
    "### 6.3. Apply initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f45554",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MODEL == '' and GAUSSIAN_INIT:\n",
    "    generator.apply(weight_init)\n",
    "    discriminator.apply(weight_init)\n",
    "    print('Gaussian init applied.')\n",
    "else:\n",
    "    print('Gaussian init not applied.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5260ea4",
   "metadata": {},
   "source": [
    "### 6.4. Move model to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa235703",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "print('Device {} is set.'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e14ad0",
   "metadata": {},
   "source": [
    "### 6.5. Define loss function and add optimizers to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c93ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "optimizer_g = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE)\n",
    "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee90f67",
   "metadata": {},
   "source": [
    "## 7. Training\n",
    "\n",
    "### 7.1. Check and create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdfe478",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isdir(Folder.MODEL_ROOT.value):\n",
    "    mkdir(Folder.MODEL_ROOT.value)\n",
    "if not isdir(Folder.GENERATOR.value):\n",
    "    mkdir(Folder.GENERATOR.value)\n",
    "if not isdir(Folder.DISCRIMINATOR.value):\n",
    "    mkdir(Folder.DISCRIMINATOR.value)\n",
    "if not isdir(Folder.SAMPLES.value):\n",
    "    mkdir(Folder.SAMPLES.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ed08a",
   "metadata": {},
   "source": [
    "### 7.3. Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_loss_g, best_epoch_loss_d = np.inf, np.inf\n",
    "for epoch in range(1, EPOCH_COUNT + 1):\n",
    "    shuffle(image_list)\n",
    "    epoch_loss_g, epoch_loss_d = 0.0, 0.0\n",
    "    g_losses, d_losses = [], []\n",
    "    b_count = 1\n",
    "    good, count = 0, 0\n",
    "    for image_files in yield_x_batches(image_list, BATCH_SIZE):\n",
    "        # Discriminator training\n",
    "        dim0 = len(image_files)\n",
    "        images = np.concatenate([load_image_np(i) for i in image_files])\n",
    "        targets = np.expand_dims(np.array([1.0 for i in range(dim0)],\n",
    "                                        dtype=np.float32), axis=1)\n",
    "        images = torch.from_numpy(images).to(device)\n",
    "        targets = torch.from_numpy(targets).to(device)\n",
    "        noise = torch.randn(dim0, RANDOM_VECTOR_DIM0, device=device)\n",
    "        fake_images = generator(noise)\n",
    "        fake_targets = np.expand_dims(np.array([0.0 for i in range(dim0)],\n",
    "                                            dtype=np.float32), axis=1)\n",
    "        fake_targets = torch.from_numpy(fake_targets).to(device)\n",
    "        optimizer_d.zero_grad()\n",
    "        d_reals = discriminator(images)\n",
    "        real_loss = criterion(d_reals, targets)\n",
    "        real_loss.backward()\n",
    "        d_fakes = discriminator(fake_images)\n",
    "        fake_loss = criterion(d_fakes, fake_targets)\n",
    "        fake_loss.backward()\n",
    "        optimizer_d.step()\n",
    "        for value in (torch.round(d_reals) == targets).detach().cpu():\n",
    "            if value:\n",
    "                good +=1\n",
    "            count +=1\n",
    "        for value in (torch.round(d_fakes) == fake_targets).detach().cpu():\n",
    "            if value:\n",
    "                good +=1\n",
    "            count +=1\n",
    "        loss_item_d = real_loss.item() + fake_loss.item()\n",
    "        for i in range(dim0):\n",
    "            d_losses.append(loss_item_d)\n",
    "        # Generator training\n",
    "        optimizer_g.zero_grad()\n",
    "        fake_images = generator(noise)\n",
    "        g_targets = np.expand_dims(np.array([1.0 for i in range(dim0)],\n",
    "                                            dtype=np.float32), axis=1)\n",
    "        g_targets = torch.from_numpy(g_targets).to(device)\n",
    "        g_preds = discriminator(fake_images)\n",
    "        generator_loss = criterion(g_preds, g_targets)\n",
    "        generator_loss.backward()\n",
    "        optimizer_g.step()\n",
    "        loss_item_g = generator_loss.item()\n",
    "        for i in range(dim0):\n",
    "            g_losses.append(loss_item_g)\n",
    "        print('\\r{:04d}/{:02d} - generator {:.8f} - discriminator {:.8f}'\n",
    "            .format(epoch, b_count, loss_item_g, loss_item_d),\n",
    "            end='')\n",
    "        b_count += 1\n",
    "    epoch_loss_d = sum(d_losses) / len(d_losses)\n",
    "    epoch_loss_g = sum(g_losses) / len(g_losses)\n",
    "    print_str = 'Epoch {:04d} - generator {:.8f} - discriminator {:.8f}'.format(epoch,\n",
    "                                                                                epoch_loss_g,\n",
    "                                                                                epoch_loss_d)\n",
    "    print_str += ' - discriminator accuracy: {:.4f}'.format(good / count)\n",
    "    print('\\r{}'.format(print_str))\n",
    "    torch.save(discriminator.state_dict(),\n",
    "          join(Folder.DISCRIMINATOR.value, 'discriminator_last.state_dict'))\n",
    "    torch.save(generator.state_dict(),\n",
    "          join(Folder.GENERATOR.value, 'generator_last.state_dict'))\n",
    "    plt.imsave(join(Folder.SAMPLES.value, 'e{:05d}.png'.format(epoch)),\n",
    "        fake_images.detach().cpu()[0, 0], cmap='bone')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
